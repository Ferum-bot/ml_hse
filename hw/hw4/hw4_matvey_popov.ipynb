{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VT3sb9cKXQ5r"
   },
   "source": [
    "# HSE 2021: Mathematical Methods for Data Analysis\n",
    "\n",
    "## Homework 4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Warning 1**: You have 2 weeks for this assignemnt.  **it is better to start early (!)**\n",
    "\n",
    "**Warning 2**: it is critical to describe and explain what you are doing and why, use markdown cells\n",
    "\n",
    "\n",
    "### Contents\n",
    "\n",
    "#### Decision Trees - 7 points\n",
    "* [Task 1](#task1) (0.5 points)\n",
    "* [Task 2](#task2) (0.5 points)\n",
    "* [Task 3](#task3) (2 points)\n",
    "* [Task 4](#task4) (0.5 points)\n",
    "* [Task 5](#task5) (0.5 points)\n",
    "* [Task 6](#task6) (2 points)\n",
    "* [Task 7](#task7) (0.5 points)\n",
    "* [Task 8](#task8) (0.5 points)\n",
    "\n",
    "#### Ensembles - 3 points\n",
    "* [Task 1](#task2_1) (1 point)\n",
    "* [Task 2](#task2_2) (0.7 points)\n",
    "* [Task 3](#task2_3) (0.5 points)\n",
    "* [Task 4](#task2_4) (0.7 points)\n",
    "* [Task 5](#task2_5) (0.1 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bbe6n5WIXQ57"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (11, 5)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Imj8aBLOXQ6A"
   },
   "source": [
    "# Part 1. Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJy0bWjhXQ6C"
   },
   "source": [
    "In this task you will be implementing decision tree for the regression by hand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKK5BxXRXQ6E"
   },
   "source": [
    "### Task 1 <a id=\"task1\"></a> (0.5 points)\n",
    "\n",
    "Here you should implement the function `H()` which calculates impurity criterion. We will be training regression tree, and will take mean absolute deviation as impurity criterion.\n",
    "\n",
    "* You cannot use loops\n",
    "* If `y` is empty, the function should return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UFHSvWgqXQ6G"
   },
   "outputs": [],
   "source": [
    "def H(y):\n",
    "    if len(y) != 0:\n",
    "      mean = np.mean(y)\n",
    "      return np.mean((y - mean) ** 2)\n",
    "    else:\n",
    "      return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "B1G2Hlt3XQ6I"
   },
   "outputs": [],
   "source": [
    "\n",
    "assert np.allclose(H(np.array([4, 2, 2, 2])), 0.75)\n",
    "assert np.allclose(H(np.array([])), 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73D2qg_KXQ6K"
   },
   "source": [
    "### Task 2 <a id=\"task2\"></a>  (0.5 points)\n",
    "\n",
    "To find the best split in the node we need to calculate the cost function. Denote: \n",
    "- `R` all the object in the node\n",
    "- `j` index of the feature selected for the split\n",
    "- `t` threshold\n",
    "- `R_l` and `R_r` objects in the left and right child nodes correspondingly\n",
    "\n",
    "We get the following cost function:\n",
    "\n",
    "$$\n",
    "Q(R, j, t) =\\frac{|R_\\ell|}{|R|}H(R_\\ell) + \\frac{|R_r|}{|R|}H(R_r) \\to \\min_{j, t},\n",
    "$$\n",
    "\n",
    "Implement the function `Q`, which should calculate value of the cost function for a given feature and threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NrSrdiHNXQ6N"
   },
   "outputs": [],
   "source": [
    "def Q(X, y, j, t):\n",
    "    size = len(X)\n",
    "    j_col = X[:, j]\n",
    "    l = y[j_col <= t]\n",
    "    r = y[j_col > t]\n",
    "    left_size = len(l)\n",
    "    right_size = len(r)\n",
    "    left_h = H(l)\n",
    "    right_h = H(r)\n",
    "    l_value = (left_size / size) * left_h\n",
    "    r_value = (right_size / size) * right_h\n",
    "    return l_value + r_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_40kYhEcXQ6P"
   },
   "source": [
    "### Task 3 <a id=\"task3\"></a>  (2 points)\n",
    "\n",
    "Now, let's implement `MyDecisionTreeRegressor` class. More specifically, you need to implement the following methods:\n",
    "\n",
    "- `best_split`\n",
    "- `grow_tree`\n",
    "- `get_prediction`\n",
    "\n",
    "Also, please add `min_samples_leaf` parameter to your class\n",
    "\n",
    "Read docstrings for more details. Do not forget to use function `Q` implemented above, when finding the `best_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "N4dscqk5XQ6R"
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self):        \n",
    "        self.right = None\n",
    "        self.left = None\n",
    "        self.threshold = None\n",
    "        self.column = None\n",
    "        self.depth = None\n",
    "        self.is_terminal = False\n",
    "        self.prediction = None\n",
    "        \n",
    "    def __repr__(self):\n",
    "        if self.is_terminal:\n",
    "            node_desc = 'Pred: {:.2f}'.format(self.prediction)\n",
    "        else:\n",
    "            node_desc = 'Col {}, t {:.2f}, Pred: {:.2f}'. \\\n",
    "            format(self.column, self.threshold, self.prediction)\n",
    "        return node_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PTsIFrinXQ6T"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "\n",
    "class MyDecisionTreeRegressor(RegressorMixin, BaseEstimator):\n",
    "    def __init__(self, max_depth=3, min_samples_split=2, min_samples_leaf=1):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "            \n",
    "    def best_split(self, X, y):\n",
    "        best_split_column = None\n",
    "        best_threshold = None\n",
    "        best_cost = H(y) \n",
    "        \n",
    "        y_l = None\n",
    "        y_r = None\n",
    "        x_l = None\n",
    "        x_r = None\n",
    "        \n",
    "        for i in range(len(X[0, :])):\n",
    "            for j in range(len(X[:, 0])):\n",
    "\n",
    "                cost = Q(X, y, i, X[j, i])\n",
    "                \n",
    "                if cost < best_cost:\n",
    "                    best_cost = cost\n",
    "                    best_split_column = i\n",
    "                    best_threshold = X[j, i]\n",
    "\n",
    "                    x_l = X[X[:,i] < best_threshold]\n",
    "                    x_r = X[X[:,i] >= best_threshold]\n",
    "                    y_l = y[X[:,i] < best_threshold]\n",
    "                    y_r = y[X[:,i] >= best_threshold]\n",
    "        \n",
    "        return best_split_column, best_threshold, x_l, y_l, x_r, y_r\n",
    "    \n",
    "    def is_terminal(self, node, y):\n",
    "        if node.depth >= self.max_depth:    \n",
    "            return True\n",
    "        if len(y) < self.min_samples_split:   \n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def grow_tree(self, node, X, y):\n",
    "        if self.is_terminal(node, y):\n",
    "            node.is_terminal = True\n",
    "            return\n",
    "   \n",
    "        best_split_column, best_threshold, x_l, y_l, x_r, y_r = self.best_split(X, y)\n",
    "        \n",
    "        if best_split_column is None:\n",
    "            node.is_terminal = True\n",
    "            return\n",
    "        if len(x_l) < self.min_samples_split:\n",
    "            node.is_terminal = True\n",
    "            return\n",
    "        if len(x_r) < self.min_samples_split:\n",
    "            node.is_terminal = True\n",
    "            return\n",
    "        \n",
    "        node.column = best_split_column\n",
    "        node.threshold = best_threshold\n",
    "        \n",
    "        node.left = Node()\n",
    "        node.left.depth = node.depth + 1\n",
    "        node.left.prediction = np.mean(y_l)\n",
    "\n",
    "        node.right = Node()\n",
    "        node.right.depth = node.depth + 1\n",
    "        node.right.prediction = np.mean(y_r)\n",
    "\n",
    "        self.grow_tree(node.left, x_l, y_l)\n",
    "        self.grow_tree(node.right, x_r, y_r)\n",
    "        \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y, accept_sparse=False)\n",
    "        self.is_fitted_ = True\n",
    "        \n",
    "        self.tree_ = Node()                             \n",
    "        self.tree_.depth = 0                            \n",
    "        self.tree_.prediction = np.mean(y)\n",
    "        \n",
    "        self.grow_tree(self.tree_, X, y)\n",
    "        return self        \n",
    "    \n",
    "    def get_prediction(self, node, x):\n",
    "\n",
    "        if node.is_terminal:\n",
    "          return node.prediction\n",
    "        \n",
    "        target = Node()\n",
    "        \n",
    "        if x[node.column] > node.threshold:\n",
    "          target = node.right\n",
    "        else:\n",
    "          target = node.left\n",
    "\n",
    "        return self.get_prediction(target, x)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = check_array(X, accept_sparse=False)\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "        \n",
    "        y_predicted = []\n",
    "        for x in X:\n",
    "            y_curr = self.get_prediction(self.tree_, x)\n",
    "            y_predicted.append(y_curr)\n",
    "        return np.array(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tm-Bzi0vXQ6b",
    "outputId": "18836b2f-fec5-4342-eec9-6a43a64f56f8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/estimator_checks.py:3617: FutureWarning: As of scikit-learn 0.23, estimators should expose a n_features_in_ attribute, unless the 'no_validation' tag is True. This attribute should be equal to the number of features passed to the fit method. An error will be raised from version 1.0 (renaming of 0.25) when calling check_estimator(). See SLEP010: https://scikit-learn-enhancement-proposals.readthedocs.io/en/latest/slep010/proposal.html\n",
      "  FutureWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/estimator_checks.py:3652: FutureWarning: As of scikit-learn 0.23, estimators should have a 'requires_y' tag set to the appropriate value. The default value of the tag is False. An error will be raised from version 1.0 when calling check_estimator() if the tag isn't properly set.\n",
      "  warnings.warn(warning_msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "\n",
    "check_estimator(MyDecisionTreeRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moOTJZ6EXQ6d"
   },
   "source": [
    "### Task 4 <a id=\"task4\"></a>  (0.5 points)\n",
    "\n",
    "Load boston dataset and split it on the train ($75\\%$) and test ($25\\%$). Fit Decision Tree of depth 1 and make the following plot:\n",
    "\n",
    "- Scatter plot of the traning points (selected for split feature on the x-axis, target variable on the y-axis)\n",
    "- Fitted model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "th_G8EKgXQ6e"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data_set = load_boston()\n",
    "\n",
    "x = data_set.data\n",
    "y = data_set.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "tree = MyDecisionTreeRegressor(2)\n",
    "tree.fit(x_train, y_train)\n",
    "\n",
    "threshold =  tree.tree_.threshold\n",
    "x_train_column = x_train[:, tree.tree_.column]\n",
    "x_test_column = x_test[:, tree.tree_.column]\n",
    "y_predcted = tree.predict(x_test)\n",
    "\n",
    "x_arr = [x_train[x_train_column <= threshold][:, tree.tree_.column],\n",
    "           x_train[x_train_column > threshold][:, tree.tree_.column],\n",
    "           x_test[x_test_column <= threshold][:, tree.tree_.column],\n",
    "           x_test[x_test_column > threshold][:, tree.tree_.column],\n",
    "           x_test[x_test_column <= threshold][:, tree.tree_.column],\n",
    "           x_test[x_test_column > threshold][:,tree.tree_.column]]\n",
    "\n",
    "y_arr = [y_train[x_train_column <= threshold],\n",
    "           y_train[x_train_column > threshold],\n",
    "           y_test[x_test_column <= threshold],\n",
    "           y_test[x_test_column > threshold],\n",
    "           y_predcted[x_test_column <= threshold],\n",
    "           y_predcted[x_test_column > threshold]]\n",
    "\n",
    "labels = ['Train left data', 'Train right data', 'Test left data', 'Test right data', 'Predicted left data', 'Predicted right data']\n",
    "\n",
    "for i in range(len(x_arr)):\n",
    "  plt.scatter(x_arr[i], y_arr[i], label=labels[i])\n",
    "\n",
    "plt.legend()\n",
    "plt.axvline(threshold)\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "mJ8pnFPNJp7Z",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 897
    },
    "outputId": "8a6bdb44-3367-439f-a44e-a9b8cfad16dc"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xwqQRMM4XQ6f"
   },
   "source": [
    "### Task 5 <a id=\"task5\"></a>  (0.5 points)\n",
    "\n",
    "Keep working with boston dataset. \n",
    "- Use `GridSearchCV` to find the best hyperparameters among [`max_depth`, `min_samples_leaf`] on 5-Fold cross-validation\n",
    "- Train the model with the best set of hyperparameters on the whole train dataset. \n",
    "- Report `MAE` on test dataset and hyperparameters of the best estimator. "
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ],
   "metadata": {
    "id": "JIb8YGcCXK49"
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "oS3Su-9rXQ6g"
   },
   "outputs": [],
   "source": [
    "params = {\"max_depth\" : range(2, 10), 'min_samples_leaf' : range(2, 10)}"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tree = MyDecisionTreeRegressor()\n",
    "tree.fit(x_train, y_train)\n",
    "\n",
    "clf = GridSearchCV(tree, params, scoring='neg_root_mean_squared_error', cv=5)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print('Best params: ', clf.best_params_)\n",
    "print('Best score: %.3f'% clf.best_score_)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1chobcmGYK2S",
    "outputId": "b86dafe2-cf26-44d1-8405-1452d5db4dbd"
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best params:  {'max_depth': 9, 'min_samples_leaf': 2}\n",
      "Best score: -4.968\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "prediction_1 = tree.predict(x_test)\n",
    "\n",
    "tree = MyDecisionTreeRegressor(max_depth=9, min_samples_leaf=2)\n",
    "tree.fit(x_train, y_train)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4aL9dnJ_hu8O",
    "outputId": "cfbf5038-4de1-4ef9-a902-d7f03ae9542c"
   },
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MyDecisionTreeRegressor(max_depth=9, min_samples_leaf=2)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "prediction_2 = tree.predict(x_test)\n",
    "\n",
    "print(\"MAE 1: \" + str(mean_absolute_error(prediction_1, y_test)))\n",
    "print(\"MAE 2: \" + str(mean_absolute_error(prediction_2, y_test)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_iOuwqtVl2Tj",
    "outputId": "44dd4fe3-9e7f-442d-c502-b45daedd2448"
   },
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MAE 1: 3.1693400799746074\n",
      "MAE 2: 2.4848923906306433\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yX49Sf4KXQ6h"
   },
   "source": [
    "### Task 6 <a id=\"task6\"></a>  (2 points)\n",
    "\n",
    "Recall definition of bias and variance:\n",
    "$$\n",
    "\\text{Bias}^2 = \\mathbb{E}_{p(x, y)} \\left[  (f(x) - \\mathbb{E}_{\\mathbb{X}}a_{\\mathbb{X}}(x))^2 \\right] \\\\\n",
    "\\text{Variance} = \\mathbb{E}_{p(x, y)} \\left[  \\mathbb{V}_{\\mathbb{X}}( a_{\\mathbb{X}}(x))  \\right]\n",
    "$$\n",
    "\n",
    "We wil now use use the following algorithm to estimate bias and variance:\n",
    "\n",
    "1. Use bootsrap to create `n_iter` samples from the original dataset: $X_1, \\dots, X_{n_iter}$\n",
    "2. For each bootstrapped sample define out-of-bag (OOB) sample $Z_1, \\dots, Z_{n_iter}$, which contain all the observations, which did not appear in the corresponding boostraped sample\n",
    "3. Fit the model on $X_i$s and compute predictions on $Z_i$s\n",
    "4. For a given *object* $n$:\n",
    "     - bias^2: squared difference between true value $y_n$ and average prediction (average over the algorithms, for which $n$ was in OOB)\n",
    "     - variance: variance of the prediction (predictions of the algorithms, for which $n$ was in OOB)\n",
    "5. Average bias^2 and variance over all the points\n",
    "    \n",
    "**Implement `get_bias_variance` function, using the algorithm above**\n",
    "\n",
    "*Note:*  You can only use 1 loop (for bootsrap iterations). All other operations should be vectorized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "cB3kwanfXQ6i",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "outputId": "6010276a-a3c7-4246-e5d4-56cf99a358fc"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m\"<ipython-input-23-b444ef55acab>\"\u001B[0;36m, line \u001B[0;32m1\u001B[0m\n\u001B[0;31m    def get_bias_variance(estimator, x, y, n_iter):\u001B[0m\n\u001B[0m                                                   ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def get_bias_variance(estimator, x, y, n_iter):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gcjrkU7hXQ6j",
    "outputId": "4e537094-2eae-4137-f599-6cc4be070bb2"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(22.374397870007858, 5.070790610978789)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "estimator = MyDecisionTreeRegressor(max_depth=8, min_samples_split=15)\n",
    "\n",
    "get_bias_variance(estimator, x_train, y_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMXT-7zeXQ6k"
   },
   "source": [
    "### Task 7 <a id=\"task7\"></a>  (0.5 points)\n",
    "\n",
    "Compute bias and variance for the trees with different min_samples_split. Plot how bias and variance change as min_samples_split increases. \n",
    "\n",
    "Comment on what you observe, how does your result correspond to theory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "n3s6Qg9PXQ6l"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdsWV0qFXQ6m"
   },
   "source": [
    "По графику можно заметить, что bias уменьшается с увеличеснием глубины, а variance почти не меняет свое значение, но можно заметить небольшое увеличение в целом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NkEWIefXQ6n"
   },
   "source": [
    "### Task 8 <a id=\"task8\"></a>  (0.5 points)\n",
    "\n",
    "Let's try to reduce variance with bagging. Use `sklearn.ensemble.BaggingRegressor` to get an ensemble and compute its bias and variance. \n",
    "\n",
    "Answer the following questions:\n",
    " - How bagging should affect bias and variance in theory?\n",
    " - How bias and variance change (if they change) compared to an individual tree in you experiments? \n",
    " - Do your results align with the theory? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "bg5ZUW3wXQ6o"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46fIyr68XQ6o"
   },
   "source": [
    "График похож на предыдущий. Bias уменьшается с увеличением глубины дерева. Variance уменьшается. В теории bias или уменьшается, или не меняется. А variance должна уменьшаться в теории. Результаты соответствуют теории."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4AT4GdzOXQ6p"
   },
   "source": [
    "# Part 2. More Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVIMAL71XQ6q"
   },
   "source": [
    "In this part we will be working with [Thyroid Disease Data Set](https://archive.ics.uci.edu/ml/datasets/thyroid+disease) to solve a classification task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqatw888XQ6q",
    "outputId": "0ac57fdc-2091-4f2d-fddb-2c9d61fc6b61",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    }
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-23-09a5300bfd2e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpreprocessing\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mLabelEncoder\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'thyroid_disease.csv'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mle\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mLabelEncoder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    310\u001B[0m                 )\n\u001B[0;32m--> 311\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    312\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    313\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    584\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    585\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 586\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    587\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    588\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    480\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    481\u001B[0m     \u001B[0;31m# Create the parser.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 482\u001B[0;31m     \u001B[0mparser\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    483\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    484\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    809\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    810\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 811\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    812\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    813\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[0;34m(self, engine)\u001B[0m\n\u001B[1;32m   1038\u001B[0m             )\n\u001B[1;32m   1039\u001B[0m         \u001B[0;31m# error: Too many arguments for \"ParserBase\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1040\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mmapping\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[call-arg]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1041\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1042\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_failover_to_python\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, src, **kwds)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m         \u001B[0;31m# open handles\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 51\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_open_handles\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     52\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhandles\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001B[0m in \u001B[0;36m_open_handles\u001B[0;34m(self, src, kwds)\u001B[0m\n\u001B[1;32m    227\u001B[0m             \u001B[0mmemory_map\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"memory_map\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    228\u001B[0m             \u001B[0mstorage_options\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"storage_options\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 229\u001B[0;31m             \u001B[0merrors\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"encoding_errors\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"strict\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    230\u001B[0m         )\n\u001B[1;32m    231\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001B[0m in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    705\u001B[0m                 \u001B[0mencoding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencoding\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    706\u001B[0m                 \u001B[0merrors\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 707\u001B[0;31m                 \u001B[0mnewline\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    708\u001B[0m             )\n\u001B[1;32m    709\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'thyroid_disease.csv'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv('thyroid_disease.csv')\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['Class'])\n",
    "X = df.drop('Class', axis=1)\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZh1SyCJXQ6t"
   },
   "source": [
    "### Task 1 <a id=\"task2_1\"></a> (1 point)\n",
    "\n",
    "Let's start with data preprocessing. \n",
    "\n",
    "0. Drop columns, which are not usefull (e.g. a lot of missing values). Motivate your choice. \n",
    "1. Split dataset into train and test\n",
    "2. You've probably noticed that we have both categorical and numerical columns. Here is what you need to do with them:\n",
    "    - Categorical: Fill missing values and apply one-hot-encoding\n",
    "    - Numeric: Fill missing values\n",
    "    \n",
    "Use `ColumnTranformer` to define a single transformer for all the columns in the dataset. It takes as input a list of tuples\n",
    "\n",
    "```\n",
    "ColumnTransformer([\n",
    "    ('name1', transform1, column_names1),\n",
    "    ('name2', transform2, column_names2)\n",
    "])\n",
    "```\n",
    "\n",
    "Pay attention to an argument `remainder='passthrough'`. [Here](https://scikit-learn.org/stable/modules/compose.html#column-transformer) you can find some examples of how to use column transformer. \n",
    "    \n",
    "Since we want to apply 2 transformations to categorical feature, it is very convenient to combine them into a `Pipeline`:\n",
    "\n",
    "```\n",
    "double_tranform = make_pipeline(\n",
    "                        transform_1,\n",
    "                        transform_2\n",
    "                        )\n",
    "```\n",
    "\n",
    "P.S. Choose your favourite way to fill missing values. \n",
    "\n",
    "*Hint* Categorical column usually have `dtype = 'object'`. This may help to obtain list of categorical and numerical columns on the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# define column_transformer "
   ],
   "metadata": {
    "id": "bJO0e-MrzACF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gN_mKdVjXQ6u"
   },
   "outputs": [],
   "source": [
    "# Transform the data\n",
    "X_train = column_transformer.fit_transform(X_train)\n",
    "X_test = column_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_v_Cn_M9XQ6v"
   },
   "source": [
    "### Task 2 <a id=\"task2_2\"></a> (0.7 points)\n",
    "\n",
    "Fit and compare 5 different models (use sklearn): Gradient Boosting, Random Forest, Decision Tree, SVM, Logitics Regression\n",
    "    \n",
    "* Choose one classification metric and justify your choice .\n",
    "* Compare the models using score on cross validation. Mind the class balance when choosing the cross validation. (You can read more about different CV strategies [here](https://scikit-learn.org/stable/modules/cross_validation.html#stratified-k-fold))\n",
    "* Which model has the best performance? Which models overfit or underfit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PXbGjcS9XQ6w"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ub2M90XRXQ6w"
   },
   "source": [
    "```your comments here```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6H47_3upXQ6x"
   },
   "source": [
    "### Task 3 <a id=\"task2_3\"></a> (0.5 points)\n",
    "\n",
    "More Gradient Boosting. You will have to implement one of the three popular boosting implementations (xgboost, lightgbm, catboost). Select hyperparameters (number of trees, learning rate, depth) on cross-validation and compare with the methods from the previous task. \n",
    "\n",
    "To get method that you have to implement, run cell below and input your name in Russian (for example, if you input Андрей, you will see that user with this name should implement xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iN3TErJ9XQ6y"
   },
   "outputs": [],
   "source": [
    "def assign_method():\n",
    "    name = input()\n",
    "    methods = ['xgboost', 'lightgbm', 'catboost']\n",
    "    idx = sum([ord(x) for x in list(name)]) % 3\n",
    "    print('Реализуйте', methods[idx])\n",
    "    \n",
    "assign_method()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9UADaXXzXQ6z"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gT53ZEzFXQ60"
   },
   "source": [
    "```your comments here```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkdfqxNBXQ60"
   },
   "source": [
    "### Task 4 <a id=\"task2_4\"></a> (0.7 points)\n",
    "\n",
    "Now let's train more fancy ensembles:\n",
    "\n",
    "* Bagging with decision trees as base estimators\n",
    "* Bagging with gradient boosting (with large amount of trees, >100) as base estimators\n",
    "* [Voting classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier) \n",
    "* [Stacking Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html#sklearn.ensemble.StackingClassifier) with Logistic Regression as a final model\n",
    "* [Stacking Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html#sklearn.ensemble.StackingClassifier) with Gradeint Boosting as a final model\n",
    "\n",
    "\n",
    "If not stated in the task, feel free to tune / choose hyperparameters and base models.\n",
    "\n",
    "Answer the questions:\n",
    "* Which model has the best performance?\n",
    "* Does bagging reduce overfiting of the gradient boosting with large amount of trees? \n",
    "* What is the difference between voting and staking? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f_l0cakvXQ61"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-tMx3B9XQ62"
   },
   "source": [
    "```your comments here```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xg81bVpMXQ62"
   },
   "source": [
    "### Task 5 <a id=\"task2_5\"></a> (0.1 points)\n",
    "\n",
    "Report the test score for the best model, that you were able to train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o0RSVZd2XQ63"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}